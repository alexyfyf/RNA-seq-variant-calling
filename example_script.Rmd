---
title: "From FASQC to Variant Calling for RNA-Seq"
author: "Anna Quaglieri"
date: "11th October 2017"
output:
  bookdown::gitbook:
  html_document:
    toc: yes
    toc_depth: 3
  github_document:
    toc: yes
    toc_depth: 3
linkcolor: magenta
urlcolor: magenta
---

```{r setup, include=FALSE,echo=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE,cache.path = "book")
```

# Setup

This is an example workflow from `SRR` files to Variant calling using modular functions written in `R` and `bash`.

```{bash engine=bash,eval=FALSE}
git clone git@github.com:annaquaglieri16/RNA-seq-variant-calling.git
```

All the functions used for the variant calling and downsampling pipeline are inside the `./functions` folder. 

* If you already have the `FASTQ` files and you don't need to randomly downsample your samples go to Section \@ref(align)
* If you already have the `FASTQ` files and you want to randomly downsample your samples to a fix number of reads go to Section \@ref(downsample)
* If you already have the `BAM` files and you want to call variants go to Section \@ref(gatk-prep)

## Disclaimer

The following workflow was built in a modular way and it is not wrapped up into a pipeline manager. I aknowledge the limitations and non-user-friendliness of some steps. However, it offers a comprehensive view of several tools and steps used for variant calling in RNA-Seq as well as general tools used in any bioinformatics pipeline.    

# Download RNA-Seq data from GEO {#download}

We will provide an example on how to download data from GEO using the Leucegene CBF-AML RNS-Seq data uploaded at https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE49642. 
The first step in dowloading data from GEO is to download the `SRA` files. For that we need to get `SRX` entries which each one corresponds to a sample in the RNA-Seq cohort.

## Get SRX sample names 

```{r message=FALSE,warning=FALSE}
library(GEOquery)
library(tidyverse)
library(knitr)
library(stringr)
```

Below is an example using one accession number from the [Leucegene data](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE49642).

```{r eval=FALSE}
dir.create("test_data",showWarnings = FALSE,recursive = TRUE)

# Get matrix files for every accession number
series_matrix_info <- function(gse){
gsed <- getGEO(gse,GSEMatrix=TRUE)
gse.mat <- pData(phenoData(gsed[[1]]))
reduced <- gse.mat[,c("title","geo_accession","relation.1")]
write.csv(reduced,file.path("test_data",paste(gse,"_",nrow(gse.mat),".csv",sep="")),row.names = FALSE)
}

series_matrix_info("GSE49642") # 43 samples
```


Every row in Table \@ref(tab:SRX) contains sample names (`title`) and `GSM` accession numbers. In order to download a particular sample we need the `SRA` terms which are the names starting with: `SRX***` in the `relation.1` column. The structure of the matrix might change across different studies but you should be able to find `SRX` entries hidden somewhere in the `GSEMatrix`!

```{r SRX,message=FALSE}
matrix_file <- list.files(path = file.path("test_data"),pattern = "GSE",full.names = TRUE)
GSEmatrix <- read_csv(matrix_file)

kable(GSEmatrix[1:5,],caption="SRX sample names.")
```

With some string processing we can extract the `SRX` entries. 

```{r message=FALSE}
GSEmatrix$SRX <- stringr::str_extract(string = GSEmatrix$relation.1,pattern = "SRX[0-9][0-9][0-9][0-9][0-9][0-9]")
GSEmatrix$relation.1 <- NULL
kable(head(GSEmatrix))
```

## Create NCBI query

```{r}
search_ncbi <- paste(GSEmatrix$SRX,collapse=" OR ")
search_ncbi
```

Paste the search `r search_ncbi` into NCBI https://www.ncbi.nlm.nih.gov/sra and follow the intructions in https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/#download-sequence-data-files-usi **Download sequence data files using SRA Toolkit** to download all the `SRR` run names and information of the runs. 

```{bash eval=FALSE}
# Files are saved in the home directory under ncbi/public/sra
prefetch --option-file SraAccList_CBF-AML_Leucegene.txt
```

SRA files can then be converted to `fastq` files with `fastq-dump --split-files`. 

# Downsampling FASTQ files {#downsample}

The [seqtk](https://github.com/lh3/seqtk) tool can be used to downsample an exact number of reads from paired end (PE) FASTQ files. The following is an example run

```{bash eval=FALSE}
path-to-seqtk-folder/seqtk sample -s100 test_data/SRR1608610_1.fastq.gz 10000 > test_data/sub_SRR1608610_1.fq
path-to-seqtk-folder/seqtk sample -s100 test_data/SRR1608610_2.fastq.gz 10000 > test_data/sub_SRR1608610_2.fq
```


# Define files and programs needed for the pipeline {#input-pipe}

* The reference genome **hg19** is used for this analysis.
* Below are all the programs and versions used

```{bash eval=FALSE}
module load STAR/2.5.2
module load R/3.4.3
module load anaconda2/4.0.0
module load sambamba/0.6.6
module load picard-tools/2.9.4
module load gatk/3.7.0
module load varscan/2.3.9
module load vcftools/0.1.13
module load samtools/1.6
module load ensembl-vep/89.0
module load vcflib/1.0.0-rc1
module load vardict/1.5.1
module load freebayes/1.1.0
module load picard-tools/2.9.4
```

* The genome references and annotations used here have been downloaded from [iGenome website](https://support.illumina.com/sequencing/sequencing_software/igenome.html) 

```{bash eval=FALSE}
# Hard link to genome.fa of the reference genome 
genome_fasta=path_to_hg19_genome_directory/genome.fa
# Hard link to gene.gtf where gene annotation is stored
gtf=path_to_hg19_gtf_directory/genes.gtf

# Functions directories
workdir=./functions

# STAR folders for one-pass, two-pass and merged output
star_1pass=./aligned_star1
star_2pass=./aligned_star2
star_merged=./star_merged_runs # Every sample comes in different SRR runs which will have to be merged in one SRX sample.
```

# FASTQC {#fastqc} and adapters trimming

`fastqc` [@Andrews2010-fk] can be used for QC of the FASTQ files.

```{bash eval=FALSE}
mkdir -p ./test_data/fastqc

fastqc ./test_data/SRR1608610_1.fastq.gz --outdir ./test_data/fastqc/
```

This is just one example to run `fastqc` on several FASTQ files using `parallel` [@Tange_undated-th].

```{bash eval = FALSE}
find ./test_data/fastqc -name "*.fastq.gz" > ./test_data/fastq_files.txt
cat ./test_data/fastq_files.txt | parallel -j 2 "fastqc {} --outdir ./test_data/fastqc"
```

I strongly suggest to have a look at [MultiQC](http://multiqc.info/) [@Ewels2016-rc] which allows you to combine together the results of multiple samples into one compact document. You can check the programs whose output is supported by `MultiQC`.

```{bash eval = FALSE}
multiqc ./test_data/fastqc --interactive -n "FASTQC_summary" -o ./test_data/
```

The `FASTQC` reports offer a variety of measures and one can decide about discarding some samples or doing some adapter trimming if necessary. [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) and [Trim Galore!](https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/) can be used for this purpose.

I suggest looking at one of my previous analysis around [adapters with STAR and Subread](https://github.com/annaquaglieri16/RNA-Seq-and-adapters--STAR-vs-Subjunc) since adapters can cause serious troubles with `STAR` default settings.


# Alignement {#align}

Once the *fastq* files are ready to be processed we can align them with *STAR*. [Subread/Rsubread](http://subread.sourceforge.net/) is another widely used RNA-Seq aligner. The reason why I initially choose *STAR* over *Subread* was simply due to the fact that *STAR* can generate specific output for chimeric reads that can be directly used with [STAR-Fusion](https://github.com/STAR-Fusion/STAR-Fusion/wiki) to analyse gene fusions. Also, *STAR* is suggested in the the [GATK Best Practices to call variants in RNA-Seq](https://gatkforums.broadinstitute.org/gatk/discussion/3892/the-gatk-best-practices-for-variant-calling-on-rnaseq-in-full-detail). 

## Create `STAR` index 

STAR requires to build an index for the reference genome that will be used in the analignment and fusion calling step.

```{bash eval=FALSE}
# TO BE DELETED
# Create Genome directory where to save STAR Index and STAR Fusion Index folders
star_genome100=path_to_genome_directory/star_index_hg19_99
star_fusion_data=path_to_genome_directory/star_fusion_hg19_dir

mkdir -p ${star_genome100}
mkdir -p ${star_fusion_data}
```


To build the *STAR index* one needs to provide the FASTA file for the reference genome used, a GTF file with information aabout the annotation and STAR also require an an extra parameter called `sjdbOverhang` which is usually set to be *(read length - 1)*. See `STAR` documentation for **Generating genome indexes** in the [STAR manual](https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf)
- 99 is (read length - 1) as described in the first section.

Below is a wrapper for `STAR` call to build an index. 

```{r eval=FALSE}
outpud_dir=./
${workdir}/build_STAR_index.sh ${genome_fasta} ${gtf} $outpud_dir "hg19" 99
```


## STAR-1pass

If you are working with a set of bamfiles, STAR developer suggests to run the alignment in a two-pass mode. This consists of first aligning all the bamfiles, collecting the *splice junctions* as output of STAR and realign all the bamfiles with this new information. For more details about 1-pass, 2-pass-multi and 2-pass-single see Section 8 of the [STAR documentation](https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf). In my pipeline I normally use the 2-pass multi strategy as below.

```{bash eval=FALSE, echo=FALSE}
# save list of fastq files into a variable
samplein_runs=$(find ${fastqdir} -maxdepth 1 -name "*1.fastq*" | sort)

for fastqin in ${samplein_runs}; do 

  FQ1=$fastqin
  FQ2=${FQ1/_1/_2}
  
  bamout=$(echo $(basename $fastqin) | cut -f1 -d "_")
  
  lock=${star_1pass}/${bamout}.lock
  
  if [[ -d ${lock} ]] ; then 
  
    echo "${bamout} is being processed"
    
  continue
    
  else
    
    mkdir -p ${lock}
    
    Rscript ${workdir}/run_STAR.R --genome_index ${star_index} --fastqfiles $FQ1,$FQ2 \
    --sampleName ${bamout} --outdir ${star_1pass} --STARmode "1Pass"
    
    rmdir ${lock}

  fi

done

```


```{bash eval=FALSE, echo=FALSE}
# If HPC is available:
# save list of fastq files into a variable
samplein_runs=$(find ${fastqdir} -maxdepth 1 -name "*1.fastq*" | sort)

for fastqin in $samplein_runs ; do

  FQ1=$fastqin
  FQ2=${FQ1/_1/_2}
  
  bamout=$(echo $(basename $fastqin) | cut -f1 -d "_") # to be personalised according to file name

  echo '#!/bin/bash' > ${star_1pass}/${bamout}_align.sh
  echo "#PBS -q submit" >> ${star_1pass}/${bamout}_align.sh
  echo "#PBS -l nodes=1:ppn=1,mem=1gb" >> ${star_1pass}/${bamout}_align.sh
  echo "#PBS -N ${bamout}" >> ${star_1pass}/${bamout}_align.sh
  echo "#PBS -o ${bamout}_out" >> ${star_1pass}/${bamout}_align.sh
  echo "#PBS -e ${bamout}_err" >> ${star_1pass}/${bamout}_align.sh
  echo  "" >> ${star_1pass}/${bamout}_align.sh
  echo 'module load STAR' >> ${star_1pass}/${bamout}_align.sh
  echo 'module load R' >> ${star_1pass}/${bamout}_align.sh
  
  echo Rscript ${workdir}/run_STAR.R --genome_index ${star_genome100} --fastqfiles $FQ1,$FQ2 \
    --sampleName ${bamout} --outdir ${star_1pass} --STARmode "1Pass" >> ${star_1pass}/${bamout}_align.sh

done


for align in ${star_1pass}/*_align.sh ; do 
  qsub ${align}
done

```


```{bash eval=FALSE}
FQ1=test_data/SRR1608907_1.fastq.gz
FQ2=test_data/SRR1608907_2.fastq.gz

Rscript ./function/run_STAR.R --genome_index star_index_hg19_99 --fastqfiles $FQ1,$FQ2 \
    --sampleName SRR1608907 --outdir ./star_1pass --STARmode "1Pass" 
```

The `R` function above is a wrapper for the STAR call below:

```{bash eval=FALSE}
module add STAR/2.5

STAR --genomeDir path_to_star_index_hg19 \
--readFilesIn $FQ1 $FQ2 --runThreadN 27 --chimSegmentMin 10 --readFilesCommand zcat --alignSJoverhangMin 8 --outBAMcompression 10 --alignSJDBoverhangMin 1 --limitBAMsortRAM 85741557872 --outFilterMismatchNmax 999 --alignIntronMin 20 --alignIntronMax 200000 --alignMatesGapMax 20000 --outFileNamePrefix path_to_star_1pass/SampleName --outSAMtype BAM SortedByCoordinate --outFilterType BySJout --outFilterMultimapNmax 15
```

To see all the arguments available:

```{bash eval=FALSE}
Rscript ./function/run_STAR.R --help
```

After running STAR on all the fastq files available we can collect all the splice junctions from the first pass and use them for the second pass.

```{bash eval=FALSE}
# concatenate splice junctions from all samples from ran in pass1
cat ./star_1pass/*SJ.out.tab > star_1pass/combined_sj.out.tab
# Dobin suggests to remove chrm cause they are usually False positives
awk '!/chrM/' ./star_1pass/combined_sj.out.tab > ./star_1pass/combined_sj_nochrM.out.tab
```

It is suggested to have a look at the summary of the alignment through *MultiQC*.

```{bash eval=FALSE}
multiqc star_1pass --interactive -n "STAR_1passQC" -o ./
```



## STAR-2pass

The second pass alignment is exactly the same as the first one with only a few differences:

- the *sjfile* input created combining the splice junctions from the first pass
- STAR is run with the option of output chimeric reads switched on. This will allow fusion analysis.

The ouput of STAR is a bamfile already sorted by coordinate with the suffix `Aligned.sortedByCoord.out.bam`. At this stage we can also run two more steps `post_align_qc1.sh` and `post_align_qc2.sh`.

```{bash eval=FALSE}
FQ1=test_data/SRR1608907_1.fastq.gz
FQ2=test_data/SRR1608907_2.fastq.gz

Rscript ./function/run_STAR.R --genome_index star_index_hg19_99 --fastqfiles $FQ1,$FQ2 \
    --sampleName SRR1608907 --outdir ./star_2pass --STARmode "2PassMulti" \
    --sjfile ./star_1pass/combined_sj_nochrM.out.tab

# Run featurecounts and collect fragment sizes for QC
./function/post_align_qc1.sh path_to_hg19_genome_directory/genome.fa \
path_to_hg19_gtf_directory/genes.gtf ./star_2pass/SRR1608907.Aligned.sortedByCoord.out.bam SRR1608907 

# Pre-process bamfile (add Read groups etc..)
./function/post_align_qc2.sh ./star_2pass/SRR1608907.Aligned.sortedByCoord.out.bam SRR1608907 \
path_to_hg19_genome_directory/genome.fa SRR1608907 >> ${script_dir}/${bamout}_align.sh

```

Details about the two post-alignment functions:

* `post_align_qc1.sh` is optional:

  1. Runs [featureCounts](http://bioinf.wehi.edu.au/featureCounts/) to get gene counts and compute PCA to evaulate the concordance between bamfiles sequenced on different lanes. This allows a QC before merging the different bamfiles into a single one.
  2. Runs [CollectMultipleMetrics](https://broadinstitute.github.io/picard/command-line-overview.html) to collect the fragment distribution of the bamfiles (only possible with PE reads). This is also a good QC to check that the fragment distribution of bamfiles on different lanes is the same. 
  
* `post_align_qc2.sh` contains necessary pre-prcessing steps:

  1. Marks PCR duplicates (using [sambamba markdup](http://lomereiter.github.io/sambamba/docs/sambamba-markdup.html))
  2. Add Read Groups to single runs before merging bamfiles (using [AddOrReplaceReadGroups](https://broadinstitute.github.io/picard/command-line-overview.html)). Even if files do not need to be merges, `GATK` requires read groups to be added bamfiles.
  3. Run [ValidateSamFile](https://broadinstitute.github.io/picard/command-line-overview.html) to check for errors in the final bamfile.

In order, its arguments are:
  
  1. **aligned bamfile**
  2. `SampleName`. This is the name of the sample applied to the `RGID` and `RGPU` fields below.
  4. `SampleName_run`. If a sample was sequenced across different lanes then these needs to be merged in one bamfile but lane-specific reag groups should be added to each separate file. This sample name will be used for the fields `RGLB` and `RGSM` in the `AddOrReplaceReadGroups` groups below.

```{bash eval=FALSE}
# Picard tool function to add read groups to a bamfile
AddOrReplaceReadGroups \
		I= ./star_2pass/SRR1608907.Aligned.sortedByCoord.out.bam \
		O= ./star_2pass/SRR1608907.Aligned.sortedByCoord.out.RG.bam \
		RGID=SRR1608907 \
		RGPU=SRR1608907 \
		RGLB=SRR1608907_run1 \
		RGPL="illumina" \
		RGSM=SRR1608907_run1
```

After running `post_align_qc2.sh` a file with the suffix `Aligned.reorderedDupl.rg.bam` will be created where read groups are added and PCR duplicated reads marked.


```{bash eval=FALSE,echo=FALSE}
# save list of fastq files into a variable
samplein_runs=$(find ${fastqdir} -maxdepth 1 -name "*1.fastq*" | sort)

for fastqin in $samplein_runs ; do

  FQ1=$fastqin
  FQ2=${FQ1/_1/_2}
  
  bamout=$(echo $(basename $fastqin) | cut -f1 -d "_") # to be personalised according to file name

  echo '#!/bin/bash' > ${star_2pass}/${bamout}_align.sh
  echo "#PBS -q submit" >> ${star_2pass}/${bamout}_align.sh
  echo "#PBS -l nodes=1:ppn=1,mem=1gb" >> ${star_2pass}/${bamout}_align.sh
  echo "#PBS -N ${bamout}" >> ${star_2pass}/${bamout}_align.sh
  echo "#PBS -o ${bamout}_out" >> ${star_2pass}/${bamout}_align.sh
  echo "#PBS -e ${bamout}_err" >> ${star_2pass}/${bamout}_align.sh
  echo  "" >> ${star_2pass}/${bamout}_align.sh
  echo 'module add STAR' >> ${star_2pass}/${bamout}_align.sh
  echo 'module load sambamba' >> ${script_dir}/${bamout}_align.sh
  echo 'module load picard-tools' >> ${script_dir}/${bamout}_align.sh
  echo 'module load R' >> ${script_dir}/${bamout}_align.sh

  echo  Rscript ${workdir}/run_STAR.R --genome_index ${star_genome100} --fastqfiles $FQ1,$FQ2 \
    --sampleName ${bamout} --outdir ${star_2pass} --STARmode "2PassMulti" \
    --sjfile ${star_2pass}/combined_sj_nochrM.out.tab >> ${star_2pass}/${bamout}_align.sh

  ######################################
  # Mark duplicates, addRG and Validate 
  ######################################
  bamin=${star_2pass}/${bamout}Aligned.sortedByCoord.out.bam
  
  echo ${workdir}/post_align_qc1.sh ${genome_fasta} ${gtf} ${bamin} ${bamout} >> ${star_2pass}/${bamout}_align.sh
  
  echo ${workdir}/post_align_qc2.sh ${bamin} ${bamout} ${genome_fasta} ${bamout} >> ${star_2pass}/${bamout}_align.sh


done



```

This time *MultiQC* will give us a summary output also of the fragment distributions and featureCounts if the output files are stored within the `star_2pass` folder.

```{bash eval=FALSE}
multiqc ./star_2pass --interactive -n "STAR_2passQC" -o ./
```

# Merge bamfiles

In some cases the sequenced reads from one sample can be sequenced across different lanes and the aligned bamfiles need to be merged. `sambamba merge` can be used for this. I created a wrapper function for it even though it assumes that the files from the same sample have a common *SampleName*. The function will merge together all bamfiles containing *SampleName*.


```{bash eval=FALSE}
${workdir}/merge_runs.sh SampleName ./star_2pass
```


# GATK pre-processing {#gatk-prep}

The pipeline contains function to call variants with `MuTect2`, `Samtools + VarScan2`, `VarDict` and `Freebayes`.
In order to run `MuTect2` some GATK pre-processing are needed. The function `function/gatk_process_pipe.R` will perform the following steps:

* *SplitNCigarReads* see [GATK documentation](https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_rnaseq_SplitNCigarReads.php)
* *Base recalibration* see [GATK documentation](https://gatkforums.broadinstitute.org/gatk/discussion/44/base-quality-score-recalibration-bqsr)

Below is an example call which wraps the steps above and check if files have already been created.


```{r echo=FALSE}

```


```{bash eval=FALSE}
Rscript ./functions/gatk_process_pipe.R \
--reference_fasta path_to_hg19_genome_directory/genome.fa \
--bamfile ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.bam --sampleName SRX381851 \
-knownSites path_to_GATK_Bundle_files/dbsnp_138.hg19.excluding_sites_after_129.vcf \
-knownSites path_to_GATK_Bundle_files/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf \
-knownSites path_to_GATK_Bundle_files/1000G_phase1.indels.hg19.sites.vcf 
```

The function above is a wrapper for the following `GATK3` calls.

## SplitNCigarReads

```{bash eval=FALSE}
gatk -T SplitNCigarReads -R path_hg19_reference/genome.fa \
-I ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.bam \
-o ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.split.bam \
--filter_mismatching_base_and_quals -U ALLOW_N_CIGAR_READS -rf ReassignOneMappingQuality -RMQF 255 -RMQT 60 \
--log_to_file path_to_star_2pass/SRR1608907_RG_DUPL_SPLIT_log
```

## Base recalibration

* Base recalibration using known sites downloaded from the [GATK Bundle](https://github.com/snewhouse/ngs_nextflow/wiki/GATK-Bundle)

```{bash eval=FALSE}
module load gatk/3.7.0

gatk -T BaseRecalibrator -R path_hg19_reference/genome.fa \
-I ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.split.bam -nct 8 \
-knownSites path_to_GATK_Bundle_files/dbsnp_138.hg19.excluding_sites_after_129.vcf \
-knownSites path_to_GATK_Bundle_files/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf \
-knownSites path_to_GATK_Bundle_files/1000G_phase1.indels.hg19.sites.vcf \
-o ./star_2pass/BaseQRecal/SRR1608907/SRR1608907_recal_data.table \
--log_to_file ./star_2pass/BaseQRecal/SRR1608907/SRR1608907_recal_step1_log 

gatk -T BaseRecalibrator -R path_hg19_reference/genome.fa \
-I ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.split.bam -nct 8 \
-knownSites path_to_GATK_Bundle_files/dbsnp_138.hg19.excluding_sites_after_129.vcf \
-knownSites path_to_GATK_Bundle_files/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf \
-knownSites path_to_GATK_Bundle_files/1000G_phase1.indels.hg19.sites.vcf \
-BQSR path_to_star_2pass/BaseQRecal/SRR1608907/SampleName_recal_data.table \
-o path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_post_recal_data.table \
--log_to_file path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_recal_step2_log 

gatk -T AnalyzeCovariates -R path_hg19_reference/genome.fa \
-before path_to_star_2pass/BaseQRecal/SRR1608907/SSRR1608907_recal_data.table \
-after path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_post_recal_data.table \
-csv path_to_star_2pass/BaseQRecal/SRR1608907/SSRR1608907_recalibration_plots.csv \
-plots path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_recalibration_plots.pdf \
--log_to_file path_to_star_2pass/BaseQRecal/SRR1608907/SRR1608907_recal_analyseCov_log 

gatk -T PrintReads -R path_hg19_reference/genome.fa \
-I ./star_2pass/SRR1608907Aligned.reorderedDupl.rg.split.bam \
-o ./star_2pass/SRR1608907Recal.reorderedDupl.rg.split.bam \
-nct 8 -BQSR ./star_2pass/BaseQRecal/SRR1608907/SRR1608907_post_recal_data.table \
--log_to_file ./star_2pass/BaseQRecal/SRR1608907/SRR1608907_Log_recalibrated_bases
```


# Variant calling {#call-variants}
\label{sec:call-variants}

You can perform variant calling on the whole genome or to a specific regions that you can specify with a `.bed` file.
Here we show how to call variants on specific regions of interest. The target regions were created using the gene symbols of the mutations listed in **Supplemental Table 3** of [@Lavallee2016-sf] and listed in `test_data/mutations_Lavallee_2016.csv`. We used the hg19 inbuilt annotation of `Rsubread` to obtain the gene ranges and added 500 bp at the end and at the beginning of each gene. The final `bed` files is `./test_data/target_regions.bed`.

View all the options in the `call_variants.R` function.

```{bash eval=FALSE}
Rscript ./functions/call_variants.R --help
```

Below is an example to run `VarDict` and `MuTect2`. The directory needed for VarDict can be downloaded from the software GitHub page https://github.com/AstraZeneca-NGS/VarDict. 


```{bash echo=FALSE}

Rscript ./functions/call_variants.R \
--reference_fasta path_hg19_reference/genome.fa \
--bamfile ./star_2pass/SRR1608907_Aligned.reorderedDupl.rg.bam \
--sampleName SRR1608907 \
--regions ./test_data/target_regions.bed \
--genome_assembly 'GRCh37' \
--VarDict_dir /home/software/VarDict \
--caller vardict \
--outputdir_suffix "defaults" \
--VEPcall 'vep --dir_cache /stornext/HPCScratch/cache/.vep --offline' \
--output_directory ./out_dir/
 
# Mutect2 call variant 
 
Rscript ./functions/call_variants.R \
--reference_fasta path_hg19_reference/genome.fa \
--bamfile ./star_2pass/SRR1608907_Aligned.reorderedDupl.rg.split.recalibrated.bam \ 
--sampleName SRR1608907 \
--regions ./test_data/target_regions.bed \
--genome_assembly 'GRCh37' \
--caller mutect \
--outputdir_suffix "defaults" \
--VEPcall 'vep --dir_cache /stornext/HPCScratch/cache/.vep --offline' \
--output_directory ./out_dir/
```

The function above wraps up calls for the callers included in the pipeline. Below are details about the actual caller settings.

## Call with MuTect2

```{bash eval=FALSE}
module load gatk/3.7.0

gatk -T MuTect2 -R path_hg19_reference/genome.fa \
-I:tumor ./star_2pass/SRR1608907_Aligned.reorderedDupl.rg.split.recalibrated.bam \
-L ./test_data/target_regions.bed \
-o test_out_dir/mutect/regions/SampleName_germline_snvs_indels.vcf \
-log test_out_dir/mutect/regions/SampleName_germline_snvs_indels_log
```

## Call with Samtools + VarScan2

```{bash eval=FALSE}
module load varscan/2.3.9
module load samtools/1.6

samtools mpileup --output-tags AD,ADF,ADR,DP,SP \
--fasta-ref -R path_hg19_reference/genome.fa \
-l ./test_data/target_regions.bed ./star_2pass/SRR1608907_Aligned.reorderedDupl.rg.split.recalibrated.bam | varscan mpileup2cns --variants 1 --output-vcf 1 --min-var-freq 0.01 > variant_calling_dir/varscan/regions/SampleName_germline_snvs_indels.vcf 2> variant_calling_dir/varscan/regions/SampleName_germline_snvs_indels_log
```

## Call with VarDict

The `teststrandbias.R` and `var2vcf_valid.pl` scripts were downloaded from https://github.com/AstraZeneca-NGS/VarDict. 

```{bash eval=FALSE}
module load vardict/1.5.1

vardict -c 1 -S 2 -E 3 -g 4 -r 2 -t -th 10 -v -G \
-R path_hg19_reference/genome.fa \
-b ./star_2pass/SRR1608907_Aligned.reorderedDupl.rg.bam ./test_data/target_regions.bed  | vardict_dir/teststrandbias.R | vardict_dir/var2vcf_valid.pl -N -E -f 0.05 >  variant_calling_dir/vardict/regions/SampleName_germline_snvs_indels.vcf
```

## Annotate variants

Below is an example using the output from VarScan but the same call is used for Mutect2 and VarDict vcf files.

```{bash eval=FALSE}
module load ensembl-vep/89.0

vep --dir_cache dir_to_VEP_cache/.vep --offline \
-i variant_calling_dir/varscan/regions/SampleName_germline_snvs_indels.vcf \
-o variant_calling_dir/varscan/regions/annotated_variants/SampleName_germline_annotated.vcf \
--cache --everything --force_overwrite --assembly GRCh37 --fork 12 --vcf --port 3337
```

## Targeted INDEL calling with `km` algorithm {#indels-km}

The [`km` algorithm](https://github.com/iric-soft/km) [@Software-km] can be adopted to have a more precise calls of INDELs. Calling INDELs from RNA-Seq is challenging and several tools have been published between 2017-2019 to accomplish this task. The `km` algorithm was benchmarked on the AML Leucegene and TCGA-LAML datasets.   


# Standardise output of variants {#variants-st}

We are now at the stage where variants are called. The scripts above helps with calling variants 
using 4 callers (VarDict, Varscan, MuTect2, km). 

At this stage, depending on how one needs to use the variants, there are several options:

## superFreq to combine time-course mutations for one patient

If you have time-course data for each patient you can use [`superFreq`](https://github.com/ChristofferFlensburg/superFreq) to analyse mutations over time; estimate the clonality development of your cancer samples; CNVs; somatic mutations etc...

Below in an example call for `superFreq`.

```{r eval=FALSE}
#!/usr/bin/env Rscript

individual = commandArgs(TRUE)[1]
print(commandArgs())
print(commandArgs(TRUE))

repos_install <- 'https://cloud.r-project.org'
RlibPath <- '/stornext/HPCScratch/home/quaglieri.a/R/x86_64-pc-linux-gnu-library/3.5'

#install.packages('devtools',repos = repos_install, lib = RlibPath)
library(devtools)
#install_github('ChristofferFlensburg/superFreq')
library(superFreq)

reference = 'path-to/genome.fa'
normalDirectory = './superFreq/referenceNormals'
metadata = './test_data/superFreq/sample-metadata.tsv'
plots = './superFreq/plots'
rdir = './superFreq/R_full_cohort'

forceRedo = forceRedoNothing()
forceRedo$forceRedoVEP = T

superFreq(metaDataFile = metadata, genome = 'hg38',captureRegions = "hg38exons.bed", plotDirectory = plots, Rdirectory=rdir, cpus=8, reference=reference, normalDirectory=normalDirectory, mode='RNA', systematicVariance=0.1, participants = "sample", forceRedo=forceRedo)

```

How the `metadata` for one patient with no matched normal samples looks like:

```{r eval=TRUE}
meta <- read_delim("test_data/superFreq/sample-metadata.tsv",delim = "\t")
knitr::kable(meta)
```

More infor on `superFreq` can be found on the GitHib page and reference manual. 

With the sample code above `superFreq` would create an `R` and `plots` folder. Within each folder it will create a folder for every patient. Following we will show how to summarise the information relative to somatic mutations and CNVs for the whole cohort allowing it to be explored with the `Mutexplore` app.  



If you decide to call variants with one of the callers above independently from the `call_variants.R` function, you still have options to standardise the `VCF` output from a caller so to explore it with the `Mutexplore` app.  
- No annotation is run -> apply function from `samplepower`
- Annotation is run -> apply function from `samplepower`
- Output is taken from superFreq -> functions from `lineplots`


# Call fusions with `STAR-Fusion` and `FusionInspector` {#fusions}

Here we suggest to ways to detect fusions from RNA-Seq samples which depends on whether one is doing an exploratory or confirmatory analysis for specific recurrent fusions (requires high sensitivity). The former analysis can be performed with [`STAR-Fusion`](https://github.com/STAR-Fusion/STAR-Fusion/wiki) and the second analysis with [`FusionInspector`](https://github.com/FusionInspector/FusionInspector/wiki) which is now integrated into `STAR-Fusion` as a sub module. `STAR-Fusion` uses the chimeric reads output from the `STAR` aligner to detect fusion trascripts. The [wiki](https://github.com/STAR-Fusion/STAR-Fusion/wiki) page of `STAR-Fusion` described how to prepare all the necessary files and software requirements to run the fusion caller. This steps are summarised in the `function/star_fusion_prepare.sh` file and they need to be run only once. 

## STAR-Fusion

In the code chunk below there is an example run of `STAR-Fusion` which is also wrapped into `function/star_fusion.sh`. The `--genome_lib_dir` argument is the path to the directory created with `function/star_fusion_prepare.sh`. For every sample aligned, `STAR` outputs the chimeric reads (for definition of chimeric reads see `STAR` manual) which are needed as input to `STAR-Fusion`. 

```{bash eval=FALSE}
sample=S1
outdir=~

${star_fusion_software_directory}/STAR-Fusion \
--genome_lib_dir ${star_fusion_data_directory} \
-J ${sample}Chimeric.out.junction \
--CPU $(nproc) \
--output_dir ${outdir}/${sample}
```

For more information about interpreting the output see `STAR-Fusion` wiki page.


## FusionInspector

```{r}

```


# Analyse time-course mutations with superFreq {#superfreq}

# Explore mutations with the `Mutexplore` Shiny app {#mutexplore}

